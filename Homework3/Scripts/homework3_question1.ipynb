{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module minidom and libraries requests, time, json.\n",
    "import requests\n",
    "import xml.dom.minidom as m\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function get_id_of_disease() was defined to return the PubmedId list of a specific disease.\n",
    "def get_id_of_disease(disease):\n",
    "    # send a GET request to the specified url, and return a response object.\n",
    "    r = requests.get(f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={disease}+AND+2019[pdat]&retmode=xml&retmax=1000\")\n",
    "    time.sleep(1)\n",
    "    # use minidom to parse strings of text from response object.\n",
    "    doc = m.parseString(r.text)\n",
    "    # get the Id elements by .getElementByTagName().\n",
    "    PubmedId = doc.getElementsByTagName('Id')\n",
    "    # create a list IdList, to save all the PubmedId.\n",
    "    IdList = []\n",
    "    # use for loop to get values of element, save into the list IdList.\n",
    "    # reference: https://stackoverflow.com/questions/317413/get-element-value-with-minidom-with-python\n",
    "    for i in range(len(PubmedId)):\n",
    "        IdList.append(PubmedId[i].firstChild.data)\n",
    "\n",
    "    return IdList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function overlap_in_two_papers() was defined, to determine whether there is a overlap in the two sets of papers.\n",
    "def overlap_in_two_papers(disease1,disease2):\n",
    "    # get the PubmedId list from disease1 and disease2, save into lists IdList1, IdList2, separately.\n",
    "    IdList1 = get_id_of_disease(disease1)\n",
    "    IdList2 = get_id_of_disease(disease2)\n",
    "    # turn list into set to remove the duplicates.\n",
    "    set1 = set(IdList1)\n",
    "    set2 = set(IdList2)\n",
    "    overlap = list(set1&set2)\n",
    "    # If there is no elements in the list overlap, there is no overlap.\n",
    "    if len(overlap) == 0:\n",
    "        print('There is no overlap in the two sets of papers that I identified.')\n",
    "    # If there is one element in the list overlap, there is a overlap.\n",
    "    elif len(overlap) == 1:\n",
    "        print(f\"There is a overlap in the two sets of papers that I identified, the Pubmed Id is {overlap[0]}.\")\n",
    "        return overlap[0]\n",
    "    # If there are more than one elements in the list overlap, there are multiple overlaps.\n",
    "    else:\n",
    "        print(f\"There are overlaps in the two sets of papers that I identified, the Pubmed Ids are{overlap}.\")\n",
    "        return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a overlap in the two sets of papers that I identified, the Pubmed Id is 32501203.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'32501203'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_in_two_papers('Alzheimers','cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function pull_metadata() was defined, to pull the metadata for each paper of a specific disease.\n",
    "def pull_metadata(disease):\n",
    "    global paper\n",
    "    # run function get_id_of_disease(), to get the PubmedId list of a specific disease. \n",
    "    IdList = get_id_of_disease(disease)\n",
    "    # create dictionary paper, to save the metadata for each paper of this disease.\n",
    "    paper = {}\n",
    "    for PubmedId in IdList:\n",
    "        # suspends execution for each second.\n",
    "        time.sleep(1)\n",
    "        # send a GET request to the url of each PubmedId and returned a response object\n",
    "        r = requests.post(f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&retmode=xml&id={int(PubmedId)}\")\n",
    "        doc = m.parseString(r.text)\n",
    "\n",
    "        # get the ArticleTitle elements by .getElementByTagName().\n",
    "        ArticleTitle = doc.getElementsByTagName('ArticleTitle')\n",
    "        Title = \"\"\n",
    "        if len(ArticleTitle) > 0:\n",
    "            # if ArticleTitle is not empty, loop through childnodes of all the elements, and get the text.\n",
    "            for elm in ArticleTitle:\n",
    "                for textmessage in elm.childNodes:\n",
    "                    try:\n",
    "                        Title += textmessage._get_wholeText()\n",
    "                    # reference: https://docs.python.org/3/tutorial/errors.html\n",
    "                    # if AttributeError is reported, check if the next childnode is a text node, and save the data into Title.\n",
    "                    except AttributeError: \n",
    "                        for subnode in textmessage.childNodes:\n",
    "                            if subnode.nodeType == m.Node.TEXT_NODE:\n",
    "                                Title += subnode.data\n",
    "        # same as AbstractText.\n",
    "        AbstractText = doc.getElementsByTagName('AbstractText')\n",
    "        Abstract = \"\"\n",
    "        if len(AbstractText) > 0:\n",
    "            for elm in AbstractText:\n",
    "                for textmessage in elm.childNodes:\n",
    "                    try:\n",
    "                        Abstract += textmessage._get_wholeText()\n",
    "                    # reference: https://docs.python.org/3/tutorial/errors.html\n",
    "                    except AttributeError: \n",
    "                        for subnode in textmessage.childNodes:\n",
    "                            if subnode.nodeType == m.Node.TEXT_NODE:\n",
    "                                Abstract += subnode.data\n",
    "\n",
    "        # reference: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&retmode=xml&id=32501203\n",
    "        MeshHeading = doc.getElementsByTagName('MeshHeading')\n",
    "        Mesh = []\n",
    "        # reference: https://stackoverflow.com/questions/6520192/how-to-get-the-text-node-of-an-element\n",
    "        if len(MeshHeading) > 0:\n",
    "            try:\n",
    "                for mesh in MeshHeading:\n",
    "                    Mesh.append(mesh.firstChild.childNodes[0].nodeValue)\n",
    "            except AttributeError: pass\n",
    "        \n",
    "        # set the dictionary key as PubmedId, dictionary values include each paper's title, abstract, MeSH terms and query.\n",
    "        paper[PubmedId] = {\n",
    "            'ArticleTitle': Title,\n",
    "            'AbstractText': Abstract,\n",
    "            'Query': disease,\n",
    "            'Mesh': Mesh\n",
    "        }\n",
    "    # return the dictionary paper.\n",
    "    return paper\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a overlap in the two sets of papers that I identified, the Pubmed Id is 32501203.\n"
     ]
    }
   ],
   "source": [
    "# save metadata of Alzheimer's into dictionary all_data, save metadata of cancers into dictionary cancer_data.\n",
    "all_data = pull_metadata('Alzheimers')\n",
    "cancer_data = pull_metadata('cancer')\n",
    "# use .update() to update the dictionary all_data, so that data from both Alzheimer's and cancer are saved.\n",
    "all_data.update(cancer_data)\n",
    "# run function overlap_in_two_papers(), to find the overlap in the two sets of papers.\n",
    "overlap_PubmedId = overlap_in_two_papers('Alzheimers','cancer')\n",
    "# change the query of this overlap into 'Alzheimer's', 'cancer'.\n",
    "all_data[overlap_PubmedId]['Query'] = \"Alzheimers or cancer\"\n",
    "\n",
    "# save the dictionary all_data into a JSON file paper.json.\n",
    "with open('paper.json','a') as f:\n",
    "    json.dump(all_data,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing code.\n",
    "# import library random.\n",
    "import random as rd\n",
    "\n",
    "# read JSON file using the open function.\n",
    "with open('paper.json') as f:\n",
    "    all_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data into alzheimer's data(alz_data) and cancer's data(cancer_data) based on content in the Query.\n",
    "alz_data = {PubmedId: data for PubmedId, data in all_data.items()\n",
    "            if data[\"Query\"] == \"Alzheimers\" or data[\"Query\"] == ['Alzheimers','cancer']}\n",
    "cancer_data = {PubmedId: data for PubmedId, data in all_data.items()\n",
    "            if data[\"Query\"] == \"cancer\" or data[\"Query\"] == ['Alzheimers','cancer']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function random_sample_for_testing() was defined to randomly select n elements from the dictionaries alz_data, cancer_data, and return the metadata of these elements(in JSON file format).\n",
    "def random_sample_for_testing(dictionary, n):\n",
    "    random_sample_dic = {}\n",
    "    for key in rd.sample(list(dictionary.keys()), n):\n",
    "        random_sample_dic[key] = dictionary[key]\n",
    "    return random_sample_dic\n",
    "\n",
    "# merge the two dictionaries.\n",
    "random_total_sample = random_sample_for_testing(alz_data,5)\n",
    "random_cancer_sample = random_sample_for_testing(cancer_data,5)\n",
    "random_total_sample.update(random_cancer_sample)\n",
    "\n",
    "# save into JSON file paper_random_sample.json.\n",
    "with open('paper_random_sample.json','a') as f:\n",
    "    json.dump(random_total_sample,f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd4c67ef142469da7dc4d338a32ac40116904d26076b8e6aa587d80720bc6a2b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
